{
 "metadata": {
  "name": "",
  "signature": "sha256:a2beba8cc7faaf2937d2bd525ad9c0fee900bb5985a82eb95afe43365bf8b333"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Calculating the topographic stress field"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In this section, we calculate the topographic stresses in an array "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import division\n",
      "import numpy as np\n",
      "import halfspace.load as hs\n",
      "import halfspace.sandbox as hbx\n",
      "import time\n",
      "import h5py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Set some path and file names.\n",
      "\n",
      "We use compressed HDF5 files for storage, using the `h5py` library."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stress_dir = '../stress_arrays/'\n",
      "b_stress_file = stress_dir + 'baloch_bouss_stress.h5'\n",
      "c_stress_file = stress_dir + 'baloch_cerr_stress.h5'\n",
      "stress_file = stress_dir + 'baloch_topo_stress.h5'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dem_file = '../test_data/dem/baloch_dem_utm41n_445m.npy'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Set up the problem"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For the current implementation of `halfspace` (v 0.5), topography and gravity are negative, and depth is positive.  Future versions of halfspace may consider topography (above sea level) and gravity as positive; this will change the coordinate system from the current left-handed system (East, North, Down) to right-handed (East, North, Up). So check the version and release notes."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rho = 2700  # density in kg m^-3\n",
      "g = 9.81    # gravitational force in m s^-2\n",
      "Fv = - rho * g\n",
      "study_res = 445 # resolution for topography, filters, etc.\n",
      "z_res = 1000\n",
      "b_conv_mode = 'valid'\n",
      "c_conv_mode = 'same'\n",
      "\n",
      "z_min = 445\n",
      "z_max = 26445\n",
      "z_len = int( (z_max - z_min) / z_res + 1)\n",
      "z_vec = np.linspace(z_min, z_max, num=z_len)\n",
      "\n",
      "kernel_rad = 1.5e5\n",
      "kernel_len = int( kernel_rad * 2 / study_res +1 )\n",
      "kernel_shape = np.array( [kernel_len, kernel_len] )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Load topography (DEM)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print('loading')\n",
      "t0 = time.time()\n",
      "topo = np.load(dem_file)\n",
      "topo *= -1 # new solutions use negative topo\n",
      "topo_shape = topo.shape\n",
      "t1 = time.time()\n",
      "print('done in', t1 - t0, 's')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "loading\n",
        "done in 0.008289813995361328 s\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Optional: pad DEM for FFT convolution"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pad_dem = True\n",
      "\n",
      "if pad_dem:\n",
      "    topo_prepad_shape = topo.shape\n",
      "    topo = np.pad(topo, kernel_len//2, mode='constant', constant_values=[0.])\n",
      "    topo_shape = topo.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Now for the automated part.\n",
      "\n",
      "All the configuration should be done above this point,\n",
      "and below this, the cells can simply be executed.\n",
      "\n",
      "Therefore, when using this guide as a template to do this work for\n",
      "different locations, you don't need to modify anything below here."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Do some configuration and make empty topo stress arrays"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "b_out_x, b_out_y = hbx.size_output(kernel_shape, topo_shape, mode=b_conv_mode)\n",
      "b_out_size = np.array( (b_out_x, b_out_y, z_len ) )\n",
      "b_stress = np.empty( (b_out_size) )\n",
      "\n",
      "b_db = h5py.File(b_stress_file)\n",
      "b_dict = {}\n",
      "comp_list = ['zz', 'xy', 'xz', 'yz', 'xx', 'yy']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Boussinesq convolution"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "t2 = time.time()\n",
      "for comp in comp_list:\n",
      "    print('working on {} stresses'.format(comp) )\n",
      "    b_dict[comp] = b_stress.copy()\n",
      "\n",
      "    for i, z in enumerate(z_vec):\n",
      "       b_dict[comp][:,:,i] = hs.do_b_convo(component=comp,  z=z, Fv=Fv,\n",
      "                                           load=topo, load_mode='topo',\n",
      "                                           conv_mode=b_conv_mode, \n",
      "                                           kernel_radius=kernel_rad,\n",
      "                                           kernel_res=study_res)\n",
      "\n",
      "    b_dict[comp] *= 1e-6  # scale results to MPa\n",
      "    \n",
      "    b_db.create_dataset('b_{}_MPa'.format(comp), data = b_dict[comp],\n",
      "                     chunks = True, compression = 'gzip')\n",
      "\n",
      "    del b_dict[comp]\n",
      "\n",
      "print('done with Boussinesq calcs in', (time.time() - t2) / 60., 'm')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "working on zz stresses\n",
        "working on xy stresses"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "working on xz stresses"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "working on yz stresses"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "working on xx stresses"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "working on yy stresses"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with Boussinesq calcs in"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5.211836250623067 m\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Cerruti convolution"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Calculate horizontal loading functions"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Boussinesq stresses for xx, xy and yy are used in the loading function\n",
      "b_xx_top = b_db['b_xx_MPa'][:,:,0] * 1e6\n",
      "b_xy_top = b_db['b_xy_MPa'][:,:,0] * 1e6\n",
      "b_yy_top = b_db['b_yy_MPa'][:,:,0] * 1e6\n",
      "b_shape = b_xx_top.shape\n",
      "\n",
      "topo = hs._centered(topo, b_shape)\n",
      "\n",
      "topo_dy, topo_dx = np.gradient(topo, study_res)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# make horizontal loading functions\n",
      "Fht_x = topo * Fv * topo_dx\n",
      "Fhb_x = b_xx_top * topo_dx + b_xy_top * topo_dy \n",
      "\n",
      "Fht_y = topo * Fv * topo_dy\n",
      "Fhb_y = b_yy_top * topo_dy + b_xy_top * topo_dx\n",
      "\n",
      "Fh_x = Fht_x + Fhb_x\n",
      "Fh_y = Fht_y + Fhb_y"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# make Cerruti output arrays\n",
      "c_x = np.zeros([topo.shape[0], topo.shape[1], z_len])\n",
      "c_y = c_x.copy()\n",
      "c_db = h5py.File(c_stress_file)\n",
      "t_db = h5py.File(stress_file)\n",
      "\n",
      "del topo # save some ram\n",
      "\n",
      "cerr_x = {}\n",
      "cerr_y = {}\n",
      "total_dict = {}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Do Cerruti convolutions"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "t3 = time.time()\n",
      "for comp in comp_list:\n",
      "    print('working on {} stresses'.format(comp))\n",
      "\n",
      "    cerr_x[comp] = c_x.copy()\n",
      "    cerr_y[comp] = c_y.copy()\n",
      "\n",
      "    for i, z in enumerate(z_vec):\n",
      "        cerr_x[comp][:,:,i] = hs.do_c_convo(component=comp, f_dir='x',z=z,\n",
      "                                            load=Fh_x, kernel_res=study_res,\n",
      "                                            kernel_radius=kernel_rad,\n",
      "                                            conv_mode=c_conv_mode) * 1e-6\n",
      "\n",
      "        cerr_y[comp][:,:,i] = hs.do_c_convo(component=comp, f_dir='y', z=z,\n",
      "                                            load=Fh_y, kernel_res=study_res,\n",
      "                                            kernel_radius=kernel_rad,\n",
      "                                            conv_mode=c_conv_mode) * 1e-6\n",
      "\n",
      "    print('saving {} data'.format(comp))\n",
      "    c_db.create_dataset('c_{}_x_MPa'.format(comp), \n",
      "                      data = cerr_x[comp], chunks=True, compression = 'gzip')\n",
      "\n",
      "    c_db.create_dataset('c_{}_y_MPa'.format(comp), \n",
      "                      data = cerr_y[comp], chunks=True, compression = 'gzip')\n",
      "\n",
      "    print('adding all results together')\n",
      "    total_dict[comp] = (b_db['b_{}_MPa'.format(comp)][:,:,:] +  cerr_x[comp] \n",
      "                        + cerr_y[comp] )\n",
      "\n",
      "    t_db.create_dataset('{}_MPa'.format(comp), data=total_dict[comp],\n",
      "                        chunks = True, compression = 'gzip')\n",
      "\n",
      "    del total_dict[comp]\n",
      "    del cerr_x[comp]\n",
      "    del cerr_y[comp]\n",
      "\n",
      "print('done with topo corrections in', (time.time() - t3) / 60., 'm')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "working on zz stresses\n",
        "saving zz data"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "adding all results together"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "working on xy stresses"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "saving xy data"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "adding all results together"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "working on xz stresses"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "saving xz data"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "adding all results together"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "working on yz stresses"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "saving yz data"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "adding all results together"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "working on xx stresses"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "saving xx data"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "adding all results together"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "working on yy stresses"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "saving yy data"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "adding all results together"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with topo corrections in"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 10.262518584728241 m\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Close HDF5 files"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "b_db.close()\n",
      "c_db.close()\n",
      "t_db.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print('done in', (time.time() - t0) / 60., 'm')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "done in 15.537505066394806 m\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Done!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The files `baloch_cerr_stress.h5` and `baloch_bouss_stress.h5` take up a lot of room, and may be deleted, unless inspection of them is desired (and if so, it may be simpler to just generate them again, rather than keep ~8 GB of somewhat useless data on hand)."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}